---
title: "[DL Basic] Optimization"
excerpt_separator: <!--more-->
categories:
  - "Boostcamp AI Tech"
tags:
  - "optimization"
  - "generalization"
  - "regularization"
use_math: true
---

### Gradient Descent (경사하강법)
- First-order iterative optimization algorithm for finding a local minimum of a differentiable function
    - 1차 미분한 값을 가지고 반복적으로 최적화시키며 국소적인 최소값을 찾는 것이 목표인 알고리즘
    
## Important Concepts in Optimization

### Generalization (일반화) 
- 학습을 시키게 되면 iteration이 증가함에 따라 보통 학습데이터에 따른 training error는 줄어들게 된다. 하지만 training error가 0이 됐다고 해서 우리가 원하는 최적값에 도달했다 보기 힘들다.
    - 학습하지 않은 데이터에 대한 test error는 오히려 떨어지게 되기 때문
- Generalization performance: training error와 test error 사이의 차이 (Generalization gap)이 작으면 작을 수록 좋다
    - 일반화 성능이 좋다는 것은 모델의 성능이 학습데이터와 비슷하게 나올 것이라 보장을 해주는 것
    - 학습데이터의 성능이 낮다면 모델의 성능도 낮게 나온다는 뜻

### Underfitting vs. Overfitting
- Underfitting: 학습을 충분히 시키지 않아 학습데이터에도 잘 동작하지 않는 현상
- Overfitting: 학습데이터에 대해 잘 동작하지만, 테스트 데이터에 대해서는 잘 동작하지 않는 현상
- Concept적인 이야기일뿐, 실제로 우리가 원하는 모델의 모습이 overfitting graph와 흡사할 수 도 있다.

### Cross-validation (k-fold validation)
- train data를 k개로 나누어 (partitioning) k-1개로 학습을 시키고 나머지 한 부분의 train data로 validation을 진행하는 방법
- parameter: 최적하여 찾고 싶은 값
- hyperparameter: 정하는 값
    - ex) learning rate, size of network, loss function, etc.
- cross validation을 사용하여 최적의 hyperparameter 결정, 그 후 모든 train data를 사용하여 학습 시작
- 학습에 대해서는 test data를 어떤 식으로라도 사용해선 안된다. 사용하는 순간 cheating! 그러므로 train data를 나누어 validation을 진행하는 것.

### Bias and Variance
- Variance: 비슷한 입력을 넣었을 때, 출력이 얼마나 일관적으로 나오는 지에 대한 수치
    - low variance: 간단한 모델
    - high variance: 비슷한 입력이 들어와도 출력이 많이 달라지기 때문에 overfitting이 될 가능성이 높음
- Bias: 분산이 적던 크던 평균적으로 봤을 때 True Target에 접근하게 되면 Bias가 낮다, True Target에서 많이 벗어나게 되면 Bias가 크다라고 본다.
- Bias and Variance Tradeoff
    - train data에 noise가 껴있다고 가정했을 때, cost를 minimize하는 것은 세 가지 파트로 나뉠 수 있다. minimize하는 값은 한 가지 값인데 그 값이 3가지 component로 이루어져 있다는 것은 세 가지 각각을 minimize한다는 것이 아니라 하나가 줄어들면 하나가 커질 수 밖에 없다는 뜻
    - cost를 이루는 세 가지는 각각 bias^2, variance, noise
    - 결국, bias를 많이 줄이게 되면 variance가 높아지게 될 가능성이 크고, variance를 높이게 되면 bias가 높아질 가능성이 크다.
    - noise가 껴있는 경우, bias와 varience를 둘다 줄이기 힘들다는 fundamental한 limitation을 보여주는 trade off
    
### Bootstrapping
- train data에서 random sampling하여 여러 개의 모델, 혹은 metric을 만들어 각 모델들이 예측하는 값들이 얼마나 일치를 이루는 지 확인하여 전체적인 모델의 uncertainty를 예측하기 위해 활용하는 방법

### Bagging vs. Boosting
- 두 가지 모두 앙상블(ensemble)이라 부르기도 한다.
- Bagging (Boostrapping aggregating)
    - Bootstrapping으로 만들어진 여러 개의 모델들의 독립적인 output을 어떤 식으로던지 평균을 내는 방법
- Boosting
    - train data를 sequential하게 보면서 부분적으로 잘 작동하는 모델들(weak-learner)을 만들어 sequential하게 합치게 되어 하나의 모델(strong-learner)을 만드는 방법
    
## Practical Gradient Descent Methods

### Gradient Descent Methods
- Stochastic gradient descent
    - batch = single sample
- Mini-batch gradient descent
    - batch = subset of data
- Batch gradient descent
    - batch = whole data
    
### Batch-size Matters
- 큰 배치 사이즈 -> sharp minimizers에 도달
- 작은 배치사이즈 -> flat minimizers에 도달 
    - flat minimizer -> Generalization performance가 높다.
    
### (Stochastic) Gradient Descent

$$W_{t+1} \leftarrow W_t - \eta g_t$$

- $W$ = weight(가중치)
- $g$ = gradient
- $\eta$ = learning rate
    - learning rate을 잡는 것이 어려움. 너무 크지도, 너무 작지도 않게 적절히 잡아주는 것이 중요

### Momentum

$$a_{t+1} \leftarrow \beta a_t + g_t$$

$$W_{t+1} \leftarrow W_t - \eta a_{t+1}$$

- $\beta$ = momentum (관성)
- $a$ = accumulation = momentum과 현재 gradient를 합친 값
- 다음 gradient가 방향을 바꾸어도 이전 gradient가 흐른 방향대로 좀더 이어 나가는 방식
- 한번 흘러간 gradient deduction을 어느정도 유지시켜주기 때문에 gradient의 방향이 자주 바뀌어도 어느정도 잘 학습이 되게끔 한다.

### Nesterov Accelerated Gradient

$$a_{t+1} \leftarrow \beta a_t + \nabla \mathcal{L}(W_t - \eta \beta a_t)$$

$$W_{t+1} \leftarrow W_t - \eta a_{t+1}$$

- $\nabla \mathcal{L}$ = Lookahead gradient
- Momentum과 차이점
    - Momentum = gradient를 계산할 때 momentum은 현재 주어진 parameter에서 gradient를 계산해서 그 gradient를 가지고 momentum을 더해주며 accumulation 계산
    - NAG = 현재의 accumulation값($a_t$)를 가지고 한 번 $W$를 계산한 뒤(이동한 뒤) 계산되어 나온 그 값의 gradient값으로 이후의 accumulation값($a_{t+1}$)을 계산한다.
- Momentum의 경우 계속 gradient를 유지하는 특성 때문에 local minima에 도달하지 못하는 현상이 있는데, 그러한 점을 이전 gradient 방향으로 먼저 가본 뒤 gradient를 계산하는 것으로 개선하여 더 빨리 local minima에 도달하게 된다.

### Adagrad

$$W_{t+1} = W_t - \frac{\eta}{\sqrt{G_t+\epsilon}}g_t$$

- $G_t$ = Sum of gradient squares
    - 지금까지의 gradient들을 제곱하여 더한 값
- $\epsilon$ = for numerical stability
    - 0으로 나뉨을 방지하기 위한 값
- parameter들이 얼마나 변했는지, 얼마나 안변했는지 확인하여 많이 변화한 parameter들에 대해서는 적게, 적게 변화한 parameter들에 대해서는 크게 변화시키는 방식
- $G_t$의 값이 계속 커지게 되면서 무한대로 가게되면 분모가 무한대가 되며 더이상 $W$의 값이 업데이트 되지 않게 된다. (학습이 점점 멈춘다는 뜻)

### Adadelta

$$G_t = \gamma G_{t-1} + (1-\gamma)g^2_t$$

$$W_{t+1} = W_t - \frac{\sqrt{H_{t-1}+\epsilon}}{\sqrt{G_t+\epsilon}}g_t$$

$$H_t = \gamma H_{t-1} + (1-\gamma)(\Delta W_t)^2$$

- $t$에 대한 window를 지정하여 $G_t$의 값이 무한히 증가하는 것(property of monotonic increasing)을 막는 방식
    - window를 10으로 지정하면 $G_t$의 값은 현재 $t$ 이전 10개의 gradient들을 제곱하여 더한 값이 된다.
- parameter가 많은 모델에서 window가 커지면 커질수록 엄청난 양의 parameter들에 대한 gradient들을 담게되기 때문에 exponential moving average(EMA)를 사용하여 $G_t$를 업데이트 해준다.
    - $\gamma$와 $1-\gamma$를 곱해주는 부분이 EMA 부분
- learning rate이 따로 존재하지 않기 때문에 우리가 바꿀 수 있는 요소가 많이 없어 adadelta는 많이 활용되지 않는다.

### RMSprop

$$G_t = \gamma G_{t-1} + (1-\gamma)g^2_t$$

$$W_{t+1} = W_t - \frac{\eta}{\sqrt{G_t+\epsilon}}g_t$$

- 논문에서 증명된게 아닌, Geoff Hinton이 강의 내에서 제안했던 방식
- adadelta에서 다시 learning rate를 넣어준 방식

### Adam (Adaptive Moment Estimation)

$$m_t = \beta_1 m_{t=1} + (1-\beta_1)g_t$$

$$v_t = \beta_2 v_{t-1} + (1-\beta_2)g^2_t$$

$$W_{t+1} = W_t - \frac{\eta}{\sqrt{v_t+\epsilon}}\frac{\sqrt{1-\beta^t_2}}{1-\beta^t_1}m_t$$

- $m_t$ = Momentum
- $\beta_1$ = momentum을 얼마나 유지시키는 가에 대한 hyperparameter
- $v_t$ = EMA of gradient squares
- $\beta_2$ = EMA에 대한 정도(window의 크기)에 대한 hyperparameter
- $\eta$ = learning rate
- $\epsilon$ = zero division error를 막기 위한 hyperparameter (e-7 default)
    - 이 값을 잘 조절해주는 것이 practical하게 중요
- $\frac{\sqrt{1-\beta^t_2}}{1-\beta^t_1}$ = unbiased estimator가 되기 위해 수학적으로 증명한 항
- gradient squares를 EMA로 가져가는 동시에 이전의 gradient 정보에 해당하는 momentum을 잘 합친 방식

## Regularization
- Generalization performance를 올리기 위해 학습에 규제를 거는 것

### Early Stopping
- validation error가 증가하려고 할 때 학습을 멈추는 방식

### Parameter Norm Penalty

$$total\ cost = loss(\mathcal{D}; W) + \frac{\alpha}{2}\lVert W \rVert^2_2$$

- $\frac{\alpha}{2}\lVert W \rVert^2_2$ = Parameter Norm Penalty or weight decay
- paremeter들의 값이 너무 커지지 않게 parameter들을 제곱하여 더한 수를 줄이는 방식
- 모델이 만들어 내는 함수의 공간(function space)속에서 함수를 최대한 부드럽게(smooth) 만들자는 의미
    - 부드러운 함수일수록 Generalization performance가 높을거라는 가정
    
### Data Augmentation
- 데이터는 언제나 많으면 많을수록 좋다.
- 기존의 데이터를 label을 바꾸지 않는 한도 내에서 변화를 시켜 데이터를 증량시키는 방식

### Noise Robustness
- input이나 weight에 noise를 넣는 방식
- 아직까지도 어떻게 Generalization performance를 올리는지 확실하게 증명되진 않았지만 Generalization gap을 줄일 수 있다는 실험적인 결과가 존재

### Label Smoothing
- 랜덤으로 선택된 두 개의 train data를 섞어주어 데이터를 증량하는 방법
- 섞어준 데이터의 label을 soft label로 지정
- 강아지와 고양이 사진을 Label Smoothing 한다고 했을 때:
    - Mix up: 강아지와 고양이를 blending하게 섞는 방식
        - label: Dog 0.5, Cat 0.5
    - Cut out: 이미지 한 장에서 이미지의 부분을 잘라내는 방식
        - label: Dog 1.0
    - CutMix: 부분적으로 이미지를 합치는 방식
        - label: Dog 0.6, Cat 0.4

### Dropout
- 추론(inference)을 할 때 모델의 dropout ratio에 따라 랜덤하게 고른 weight를 0으로 바꾸는 것

### Batch Normalization
- batch normalization을 적용하고자 하는 layer의 statistics(mean, variance)를 정규화하는 것
    - 평균을 빼주고, 표준편차로 나눠줌으로써 zero mean, unit variance를 만든다.
- internal covariate shift를 줄임으로써 모델이 잘 학습을 하게 된다라는 논문이 존재하지만 후에 나오는 많은 논문들이 그에 동의하진 않는다.
- 여러가지 normalization이 존재한다
    - Batch, Layer, Instance, Group