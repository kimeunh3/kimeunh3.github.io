---
title: "[AI Math] 베이즈 통계학 맛보기"
excerpt_separator: <!--more-->
categories:
  - "Boostcamp AI Tech"
tags:
  - "conditional probability"
  - "bayes' theorem"
  - "causality"
use_math: true
---

### 조건부 확률
- $P(A \mid B) = $ 사건 B가 일어난 상황에서 사건 A가 발생할 확률  
    
    $$= P \left (\frac{A \cap B}{B} \right)$$  
    
    $$=\frac{P(A \cap B)}{P(B)}$$

- 위의 식에서 다음과 같은 정의를 얻을 수 있다.  
    
    $$P(A \cap B) = P(B)P(A|B)$$  

- 베이즈 정리  
    
    $$P(B \mid A) = \frac{P(A \cap B)}{P(A)} = P(B)\frac{P(A \mid B)}{P(A)}$$
    
    $$P(\theta \mid \mathcal D) = P(\theta) \frac{P(\mathcal D \mid \theta)}{P(\mathcal D)}$$

- $\mathcal D$ = 새로 관찰하는 데이터
- $\theta$ = hypothsis, 모델링하는 event, 모델에서 계산하고 싶은 모수(parameter)
- $P(\theta \mid \mathcal D)$ = 사후확률 (posterior)
    - 데이터가 주어져 있을 때, 이 hypothsis, 혹은 event($\theta$)가 성립할 확률
    - 데이터를 관찰한 이후에 측정하는 확률이기 때문에 사후확률이라고 함
- $P(\theta)$ = 사전확률 (prior)
    - 데이터를 분석하기 전에 hypothsis, 혹은 event($\theta$)에 대해 가정해두는 확률분포
- $P(\mathcal D \mid \theta)$ = 가능도 (likelihood)
    - 현재 주어진 모수(parameter)에서 그 데이터가 관찰될 확률
- $P(\mathcal D)$ = Evidence
    - 데이터 자체의 분포
    
### 베이즈 정리: 예제
- $P(\theta)$ = COVID-99의 발병률이 10% = 0.1
- $P(\mathcal D \mid \theta)$ = COVID-99에 실제로 걸렸을 때, 검진될 확률은 99% = 0.99
- $P(\mathcal D \mid \neg\theta)$ = COVID-99에 실제로 걸렸을 때, 오검진될 확률이 1% = 0.01
- 질병에 걸렸다고 검진결과가 나왔을 때 정말로 COVID-99에 감염되었을 확률? $\rightarrow$ $P(\theta \mid \mathcal D)$
    - 사전확률, 민감도(Recall), 오탐율(False alarm)을 가지고 정밀도(Precision)을 계산하는 문제

    $$P(\mathcal D) = \sum_\theta P(\mathcal D \mid \theta)P(\theta)$$

    $$= P(\mathcal D \mid \theta)P(\theta) + P(\mathcal D \mid \neg\theta)P(\neg\theta)$$
    
    $$= 0.99 \times 0.1 + 0.01 \times 0.09 = 0.108$$
    
    $$P(\theta \mid \mathcal D) = P(\theta) \frac{P(\mathcal D \mid \theta)}{P(\mathcal D)}$$
    
    $$=0.1 \times \frac{0.99}{0.108} \approx 0.916$$
    
- 만약 오검진될 확률이 1%가 아니라 10%라면?

    $$P(\mathcal D) = \sum_\theta P(\mathcal D \mid \theta)P(\theta)$$

    $$= P(\mathcal D \mid \theta)P(\theta) + P(\mathcal D \mid \neg\theta)P(\neg\theta)$$
    
    $$= 0.99 \times 0.1 + 0.1 \times 0.09 = 0.189$$
    
    $$P(\theta \mid \mathcal D) = P(\theta) \frac{P(\mathcal D \mid \theta)}{P(\mathcal D)}$$
    
    $$=0.1 \times \frac{0.99}{0.189} \approx 0.524$$
    
    - 오탐율(False alarm)이 오르면 테스트의 정밀도(Precision)가 떨어진다.

- Confusion Matrix

    ![image](https://user-images.githubusercontent.com/59808674/196392799-36307e0c-5d4c-49b9-91b8-786877bd1b90.png)  

    - True Positive: 양성이 나왔을 때, 실제로 걸렸을 확률
    - True Negative: 음성이 나왔을 때, 실제로 걸리지 않았을 확률
    - False Positive(1종 오류): 양성이 나왔을 때, 실제로 걸리지 않았을 확률
    - False Negative(2종 오류): 음성이 나왔을 때, 실제로 걸렸을 확률
    - $P(\theta \mid \mathcal D)$ 정밀도(Precision) $= \frac{TP}{TP+FP}$
        - 오탐률(False alarm)을 줄일 경우, 분모에 들어가는 False Negative의 값이 줄어들기 때문에 정밀도가 올라가게 된다.

### 베이즈 정리를 통한 정보의 갱신
- 새로운 데이터가 들어왔을 때, 앞서 계산한 사후확률을 사전확률로 사용하여 갱신된 사후확률을 계산 가능
- 오검진될 확률이 10%일 때의 경우에서, 두 번째 검진을 받았을 때도 양성이 나왔을 때, 실제로 걸렸을 확률은?
    - 이전에 계산된 사후확률($P(\theta \mid \mathcal D) \approx 0.524$)를 이번 연산에서 사전확률($P(\theta)$)에 대입하여 계산

    $$P(\mathcal D^\prime) = \sum_\theta P(\mathcal D \mid \theta)P(\theta)$$

    $$= P(\mathcal D \mid \theta)P(\theta) + P(\mathcal D \mid \neg\theta)P(\neg\theta)$$
    
    $$= 0.99 \times 0.524 + 0.1 \times 0.476 \approx 0.566$$
    
    $$P(\theta \mid \mathcal D^\prime) = P(\theta) \frac{P(\mathcal D \mid \theta)}{P(\mathcal D^\prime)}$$
    
    $$=0.524 \times \frac{0.99}{0.566} \approx 0.917$$

### 조건부 확률과 인과관계
- 조건부 확률은 유용한 통계적 해석 또는 검증을 제공하지만 인과관계(causality)를 추론할 때 함부로 사용해선 X
    - 데이터가 많아져도 조건부 확률만으로 인과관계 추론 불가능
- 인과관계는 데이터 분포의 변화에도 일관된 결과를 내는 예측모형을 만들 때 필요
    - 조건부확률 기반 예측모형은 학습데이터와 유사한 데이터에서는 높은 정확도를 낼 수 있지만, 조금만 데이터가 달라지게 되면 정확도가 감소하게 됨
    - 인과관계 기반 예측모형은 높은 정확도를 기대하긴 어렵지만 시나리오에 상관없이 일관된 정확도를 보여줌 
- 인과관계를 알아내기 위해서는 중첩요인(confounding factor)의 효과를 제거 후 원인에 해당하는 변수만의 인과관계를 계산
    - 중첩요인(confounding factor): 인과관계를 알아내려 하는 두 변수에 동시에 영향을 주는 요인
        - 중첩요인을 제거하지 않을 경우 가짜 연관성(spurious correlation)이 나오게 됨
    - 키와 지능지수 사이의 인과관계를 확인할 때, 키가 클수록 지능지수가 높다는 결과값이 나오게 되는데 이것은 연령(나이)이라는 중첩요인을 제거하지 않았기 때문에 나오게 되는 가짜 연관성이다.